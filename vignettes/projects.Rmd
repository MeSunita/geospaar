---
title: "Semester Projects"
author: "Lyndon Estes"
date: "`r Sys.Date()` [Back to home](index.html)"
output:
  rmdformats::readthedown:
    highlight: pygments
    number_sections: yes
    toc_depth: 3
    css: unit.css
vignette: >
  %\VignetteIndexEntry{Projects}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview{#overview}

Each student will undertake an R-based final project for this class. This project could be one related to your own thesis work, which we will discuss and agree upon. Otherwise, there is a a list of [potential projects below](projects.html#project-list), which are related to ongoing research projects.  

There are two parts to the final project: 1) the project overview; 2) the final project itself. 

# Project overview assignment 

As the first step in the first assignment purpose of this assignment is to provide a plan for your semester final project.

## Set-up
We say goodbye to the repos/packages used for assignments 1-5 (e.g. your version of `xyza1`). Start a new package with a Git/GitHub repo, naming it something short but descriptive of the project you are doing. Follow the R package naming conventions to setup your repo name. This should be a private repo under the agroimpacts organization. 

As with your previous assignments, your work should be structured as an R package. That does not mean that you will necessarily need to be writing functions that are native to the package (i.e. documented functions living in the R folder that build with the package), but you should be writing your project up and showing your code and analysis within vignettes.  

## Tasks

For this assignment, you should write a single vignette called "overview.Rmd", which has the following sections: 

1. Summary: A brief (up to 250 words) description of the project, and a bullet point or enumerated list of its primary objectives. 

2. Approach and Method: An outline of the analytical methods and code you plan to use, including the names of key packages that you will draw on. This section should be composed of the following sub-sections: 

3. Data: A brief (~250 words) description **and** visualization of the datasets you will be using. That means spatial plots of the main datasets and their key values, and, as a bonus, a plot of summary statistics, e.g. a histogram or boxplot of one of the more importants variables in the dataset.  

4. Code: A bullet point summary of the analysis and coding approach that you propose to follow. For teams, this section should include a description of which member will be responsible for each bullet point. 

5. Timelines: Provide a timeline for when each portion of the analysis will be completed. These timelines should be constructed relative to the time period of presentations (during the last two weeks of class) and final project submission (during exam week). For teams, names should be associated with each step on the timeline. 

6. Anticipated outcomes: Briefly describe, as bullet points, the outcomes you expect for each of your primary project objectives

## An additional note for teams
For this last assignment, it doesn't make sense that team members do separate work in different branches of the repo, with the exception of cases where data fetching and wrangling tasks needed to describe and visualize the data are partitioned between members. In this case, team members should have separate vignettes in their respective branches describing the data gathering and processing steps to date. Otherwise, the expectation is that this assignment is presented as a jointly written vignette that builds with the package in the master branch. Please put your initials next to sections that you were responsible for writing. If you want to get really advanced, you can each jointly work on a version of overview in your own branches, and then do a merge and reconcile of your differing version in the master branch. 
***
<center>
[Back to home](index.html)
</center>
***

# Final project
The following are the requirements and assessment approach for the final project:

## Overall scope

The purpose of the final product is to provide an overview of the results of the project you have been working on during the final unit of the class, building on the work you will have already presented in class during one of the last four sessions. The nature of this product can vary according to the type of project you are pursuing, which I would broadly define into two groups: 

1. Those that are more focused on developing a package that provides a set of R functions that will be more broadly useful; 

2. Those that are more analytical in nature, i.e. using R to answer particular questions of interest. 

In the former case, we will want to see a good presentation of worked examples presented in your package vignette(s). In the latter case, your package vignette(s) should give an informative overview of your key findings and (if applicable) way forward for the project. Some projects may fall somewhere in between these two extremes.    

## Structure and content

Regardless of the type of project you are developing, you will submit it as an R package, as we have been doing all semester. That R package should be fully reproducible, i.e.

```{r, eval = FALSE}
devtools::install_github("agroimpacts/yourproject", build_vignettes = TRUE)
browseVignettes("yourproject")
```

Works perfectly and gives us results that contain everything we need to evaluate the project. Datasets that are too large to be committed to the package repo should be linked to, but the code used to process them should be clear, and any figures built from them should be committed to the repo and incorporated in your package vignettes. Vignettes will contain the material we are most interested in, but we will also examine your DESCRIPTION, NAMESPACE, function documentation (if applicable), i.e. the key components of making an R package and delivering it in a reproducible manner. 

Jointly authored vignettes in group projects should have team member initials indicating which section each member worked on which section. Otherwise, separately authored ones should have team member titles at the top.  

As stated before, if there are clear, separable tasks that lend themselves to separate development efforts, team members should work on those and make frequent commits within their own repo branches. 

R code should follow the [style](http://adv-r.had.co.nz/Style.html) we have been using all along. 

The main item in your package that we will assess is/are the package vignette/vignettes. 

## Vignette(s)

You can choose to have one or several vignettes, depending on how much sense it makes to break down the information into separate documents. Regardless, your vignette or vignettes should contain the following information (the names of the headings can vary though according to what makes sense)

### Introduction (or Overview)
A more detailed and informative overview of the project's purpose and objectives than what your provided in assignment 6. Approximate maximum length of 400 (individual) to 800 (team, assuming a single package vignette) words.  

### Methods (or Approach)

For a more analytical project, provide a complete description of the methods you used to undertake the analysis, complete with informative illustrations and summaries of the input datasets. Approximate maximum length of 400 (individual) to 800 words. 

For a project that is more tools-oriented, use this section to describe the purpose and rationale of the functions/capabilities you are developing, what other packages/software/tools it is building on, and provide informative illustrations and summaries of the dataset(s) you are using to demonstrate your functions. Same approximate length. 

### Results (Worked Examples)

For analytical projects, describe and illustrate your results, using standard scientific reporting conventions: 1) plan on having 2-4 figures; 2) a similar number of statistical summaries; 3) describe the results in your figures and tables in (up to) 400-800 words (range refers to individual versus team efforts). 

For tools-oriented projects, provide and illustrate 2-4 worked examples of how to use the functions in your package, with descriptive accompanying text that will help users to understand what the functions do and how to apply them (up to 400-800 words; range refers to individual versus team efforts). 

### Discussion

For analytical projects, briefly provide your interpretation of the results, any uncertainties/difficulties encountered, and any next steps to be taken. Up to 400-800 words (range refers to individual versus team efforts).

For tools-oriented projects, describe any limitations of the package, improvements that can be made, and any plans to undertake these. Up to 400-800 words (range refers to individual versus team efforts).  


Alternatively, you can choose to undertake one of the projects listed below. 

This list is currently in thumbnail form, and will fill out during the next few weeks. 

# Potential project list{#project-list}
## USF projects
The following projects build upon data developed for an ongoing project funded by the Urban Studies Foundation, which is found in the [`USF` repo](https://github.com/agroimpacts/USF):

### Identifying potential risky locations for San Francisco property crime

The `USF` package has information on historic crime and land use data for San Francisco, for the years 2007 and 2019. The purpose of this assignment is to critically assess what leads the police to surveil some spaces more than others. An analysis of what type of locations are deemed risky will shed some light on the factors that bias police activity by questioning the assumption that some spaces attract more crime than others. For this assignment, clean up the crime dataset and create a variable for property crime (as defined by to the [National Institute of Justice](https://nij.ojp.gov/topics/crime/property-crimes)) for both years. With historical land use data, identify what these locations might be (`property_class_code_definition` for specifics on land use and `use_definition` to group by categories). A socioeconomic analysis (census data) would add more layers to the analysis.

### Temporal analysis of crime for San Francisco. 

With the `USF` crime data for the years 2007 and 2019, this project would identifying which areas of San Francisco are riskier at what times of the day/season. How is the temporal distribution of crime in 2007 different from 2019, for either property crime or general crime. This analysis could be based on police districts, while a socioeconomic analysis (census income, population data) that goes with the temporal analysis would add context to the areas that appear to be "risky".

### Can surveillance floodlighting be detected using VIIRS nightlights?
Using known [locations and dates](https://due-parsons.github.io/methods3-fall2017/projects/comparative-location-data-of-nypd-lighting-in-harlem/) of floodlight deployments from Harlem: 

1. Part 1

    - Collect time series of VIIRS night light data from Google Earth Engine (using `rgee`) over those points on a long-ish time series on either side of the deployment dates
    - Calculate the size of the night light anomalies for those points for date intervals covering the deployments


2. Part 2

    - Collect night lights over locations and around and through dates of known Black Lives Matters protests. 
    - Repeating the part 1 analysis, are nightlight anomalies visible around those locations and dates


3. Part 3

    - Collect night lights over public housing projects and neighborhoods of similar structure and population density
    - Is there a difference in night light intensities between the two groups?


## Analyzing Ghanaian croplands 
The [Mapping Africa](http://mappingafrica.io) project has recently used an integrated crowdsourcing/machine learning platform to map Ghana's croplands at high resolution. The resulting outputs include vector representations of field boundaries, as well as 3 m cropland probabilities, divided into ~8,000 0.05$^\circ$ tiles. This is a large and rich dataset, and there are a number of possible projects that can be made from this. Among the potential projects are: 
### Evaluating field characteristics over three years
Use three years (2018, 2020, and 2021) of field boundary data in Central Ghana to assess the average size of fields (is there any change over time?) and how much fields shift from year to year.

## Analyzing agro-climatological data 
### Over Zambia
#### Quantify Zambia's maize planting season
Use the SMS data to analyze the start and end of the maize planting season and how that varies across Zambia, for the 2016-2017 growing season. Do the same using vegetation index curves over known cropland locations, extracted from GEE using the `rgee` packaged, with start and end of season identified using percentiles relative to peak and other metrics. How well do SMS and VI-based planting date estimates correspond? How long was the season from planting to harvest?  What was the average start date, and how did it vary throughout the country? What was the average harvest date, and how did it vary throughout the country?

#### Evaluate the skill of gridded weather products
Compare the incoming shortwave solar radiation, temperature, and other variables measured by our new sensor pod network to comparable remotely sensed datasets. How well do the various temperature measures correlate with MODIS's Land Surface Temperature (LST)? Is MODIS LST good enough for measuring daily air temperatures at fine scales? How well do the sensors' incoming shortwave radiation correlate with gridded solar radiation datasets (e.g. NASA Power)?  

### Do farming communities vary their planting dates to adapt to rainfall uncertainty? 
Put another way, do farming communities in areas with higher rainfall variability show higher variability between farmers in terms of when crops are planted?  We hypothesize that this might be the case, as it might be a community-level adaptive response for dealing with climatic uncertainty.  

This analysis would be undertaken using remotely sensed datasets: NDVI time series, gridded rainfall datasets, and a cropland mask. The NDVI time series are processed into values that identify the date of green-up over ~18 years. The rainfall data should be used to calculate the coefficient of variation (CV) of rainfall in the first 2 months of the growing season, and the long-term mean rainfall. Comparing croplands from areas of similar mean rainfall, see if there is a relationship between CV of rainfall and CV of green-up date. 

## In Sutton, MA
Continuing analyses of UAS, satellite, and sensor datasets collected during the past four summers in Sutton MA. 

Among possible ideas are Shiny dashboards for: 1) displaying pod data over time; 2) displaying "cones of uncertainty" from projected crop yield simulations.

## Using UAS to detect the spread of a crop disease

Use R-implemented machine learning techniques to classify fungal blight in UAS time series collected over cranberry bogs in New Jersey. Projects during previous semesters developed deep learning models in `R` for this purpose. These can be built upon and improved during this semester. 

## Map visualization
Come up with `shiny` solution for presenting and analyzing map data, for any of these projects. 

